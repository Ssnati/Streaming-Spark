# Web Scraper + Spark Streaming - FincaraÃ­z

Proyecto completo que demuestra web scraping y procesamiento en tiempo real con Spark Streaming para propiedades inmobiliarias.

## ğŸš€ CaracterÃ­sticas

### 1. Web Scraping BÃ¡sico
- ExtracciÃ³n de propiedades desde FincaraÃ­z Colombia
- PaginaciÃ³n automÃ¡tica (5 pÃ¡ginas)
- Datos guardados en CSV

### 2. Spark Streaming (â­ NUEVO)
- Procesamiento de datos en tiempo real
- MÃºltiples anÃ¡lisis simultÃ¡neos
- GeneraciÃ³n de datos sintÃ©ticos para demo

## ğŸ“¦ InstalaciÃ³n

### OpciÃ³n 1: Dependencias completas
```bash
pip install -r requirements.txt
```

### OpciÃ³n 2: Solo dependencias esenciales
```bash
pip install -r requirements-min.txt
```

### OpciÃ³n 3: Solo para Spark Streaming
```bash
pip install pyspark pandas
```

## ğŸ¯ Uso

### ğŸš€ PUNTO DE ENTRADA PRINCIPAL (RECOMENDADO)
```bash
python main.py
```

### Opciones Individuales

#### Web Scraping BÃ¡sico
```bash
python scraping/Spark.py
```

#### ğŸ”¥ Demo Spark Streaming
```bash
cd spark
python spark_streaming_demo.py
```

#### Sistema Completo
```bash
cd spark
python streaming_coordinator.py
```

## ğŸ“Š AnÃ¡lisis de Spark Streaming

El sistema ejecuta 5 anÃ¡lisis en tiempo real:

1. **ğŸ“‹ Todas las propiedades** (cada 10s)
   - Muestra propiedades procesadas en tiempo real

2. **ğŸ“ EstadÃ­sticas por ubicaciÃ³n** (cada 15s)
   - Precio promedio, mÃ¡ximo, mÃ­nimo por zona
   - NÃºmero total de propiedades

3. **ğŸ  AnÃ¡lisis por tipo** (cada 20s)
   - Casa vs Apartamento vs Duplex
   - Precio y Ã¡rea promedio por tipo

4. **ğŸ’° Mejor relaciÃ³n calidad-precio** (cada 25s)
   - Propiedades ordenadas por precio/mÂ²
   - Detecta las mejores ofertas

5. **â­ Alertas propiedades premium** (cada 30s)
   - Propiedades > $500M COP
   - CaracterÃ­sticas de lujo

## ğŸ“ Estructura del Proyecto

```
ğŸ“ Electiva-4/
â”œâ”€â”€ ğŸ“„ main.py                    # ğŸ¯ PUNTO DE ENTRADA PRINCIPAL
â”œâ”€â”€ ğŸ“„ README.md                  # DocumentaciÃ³n completa
â”œâ”€â”€ ğŸ“„ requirements-min.txt       # Dependencias esenciales
â”œâ”€â”€ ğŸ“„ requirements.txt           # Todas las dependencias
â”œâ”€â”€ ğŸ“„ .gitignore                 # ConfiguraciÃ³n Git
â”‚
â”œâ”€â”€ ğŸ“ scraping/                  # MÃ³dulos de web scraping
â”‚   â”œâ”€â”€ ğŸ“„ __init__.py           # InicializaciÃ³n del mÃ³dulo
â”‚   â”œâ”€â”€ ğŸ“„ Spark.py              # Scraper bÃ¡sico de FincaraÃ­z
â”‚   â””â”€â”€ ğŸ“„ detailed_scraper.py   # Scraper detallado individual
â”‚
â”œâ”€â”€ ğŸ“ spark/                     # MÃ³dulos de Spark Streaming
â”‚   â”œâ”€â”€ ğŸ“„ __init__.py           # InicializaciÃ³n del mÃ³dulo
â”‚   â”œâ”€â”€ ğŸ“„ spark_streaming_app.py      # Motor de Spark Streaming
â”‚   â”œâ”€â”€ ğŸ“„ spark_streaming_demo.py     # ğŸ¯ Demo completo
â”‚   â”œâ”€â”€ ğŸ“„ synthetic_data_generator.py # Generador de datos
â”‚   â””â”€â”€ ğŸ“„ streaming_coordinator.py    # Coordinador del sistema
â”‚
â””â”€â”€ ğŸ“ data/                      # Datos y archivos generados
    â”œâ”€â”€ ğŸ“„ __init__.py           # InicializaciÃ³n del mÃ³dulo
    â”œâ”€â”€ ğŸ“„ propiedades.csv       # Datos de propiedades
    â”œâ”€â”€ ğŸ“„ html_response_*.html  # Respuestas HTML guardadas
    â””â”€â”€ ğŸ“ streaming_data/       # Datos para Spark (se crea automÃ¡ticamente)
```

## ğŸ® GuÃ­a RÃ¡pida

### Para probar todo el sistema (2 minutos):
```bash
# 1. Instalar dependencias
pip install -r requirements-min.txt

# 2. Ejecutar menÃº principal
python main.py

# 3. Seleccionar opciÃ³n 2 (Demo Spark Streaming)
# 4. Â¡Ver la magia! ğŸ‰
```

### Para scraping real de FincaraÃ­z:
```bash
# Desde el menÃº principal
python main.py
# Seleccionar opciÃ³n 1 (Web Scraping bÃ¡sico)
```

## ğŸ”§ Requisitos del Sistema

- **Python**: 3.7 o superior
- **Java**: 8 o 11 (para PySpark)
- **RAM**: MÃ­nimo 4GB recomendado
- **SO**: Windows/Linux/macOS

## ğŸ“ˆ Datos Generados

### CSV BÃ¡sico (`data/propiedades.csv`)
- title, price, location, rooms, bathrooms, area_m2, publisher, url

### Streaming JSON (formato enriquecido)
- Todos los campos anteriores +
- timestamp, property_type, amenities, condition, construction_year
- price_per_m2, floors, parking, description

## ğŸ¯ Casos de Uso Demostrados

1. **ETL en Tiempo Real**: ExtracciÃ³n, transformaciÃ³n y carga continua
2. **AnÃ¡lisis de Mercado**: EstadÃ­sticas de precios en vivo
3. **Alertas AutomÃ¡ticas**: DetecciÃ³n de propiedades premium
4. **Calidad de Datos**: Limpieza y validaciÃ³n en streaming
5. **Agregaciones Complejas**: MÃºltiples mÃ©tricas simultÃ¡neas

## ğŸš¨ Troubleshooting

### Error: "Java not found"
```bash
# Instalar Java 11
# Windows: Descargar desde Oracle/OpenJDK
# Linux: sudo apt install openjdk-11-jdk
# macOS: brew install openjdk@11
```

### Error: "No module named pyspark"
```bash
pip install pyspark==3.4.1
```

### Sin datos en streaming
```bash
# Desde el menÃº principal, seleccionar opciÃ³n 4
python main.py
```

## ğŸ“ Notas Importantes

- **Streaming Data**: Los archivos JSON se generan en `data/streaming_data/`
- **Rate Limiting**: 2 segundos entre requests para respetar el servidor
- **Memory**: Spark usa ~2GB RAM por defecto
- **Performance**: Mejor rendimiento con SSD
- **Estructura Modular**: CÃ³digo organizado en mÃ³dulos especÃ­ficos

## ğŸ“ Conceptos Demostrados

### Web Scraping
- **Beautiful Soup**: Parsing de HTML
- **Requests**: Manejo de HTTP
- **Rate Limiting**: Respeto al servidor
- **Error Handling**: Manejo de errores robusto

### Spark Streaming
- **Structured Streaming**: API moderna de Spark
- **Micro-batch Processing**: Procesamiento por lotes pequeÃ±os
- **Window Functions**: AnÃ¡lisis temporal
- **Multiple Sinks**: MÃºltiples outputs simultÃ¡neos
- **Schema Evolution**: Manejo de cambios de estructura

### Arquitectura de Software
- **Modularidad**: SeparaciÃ³n clara de responsabilidades
- **Escalabilidad**: FÃ¡cil agregar nuevas fuentes
- **Mantenibilidad**: CÃ³digo organizado y documentado

---

## ğŸ† Â¿Por quÃ© este proyecto es ideal para demostrar Spark Streaming?

1. **âœ… Datos Realistas**: Propiedades inmobiliarias reales
2. **âœ… Flujo Continuo**: Datos llegan gradualmente
3. **âœ… AnÃ¡lisis Variados**: 5 tipos diferentes de consultas
4. **âœ… Escalabilidad**: FÃ¡cil agregar mÃ¡s fuentes de datos
5. **âœ… VisualizaciÃ³n**: Resultados claros en consola
6. **âœ… PrÃ¡ctica Real**: Caso de uso empresarial tÃ­pico
7. **âœ… CÃ³digo Organizado**: Estructura profesional modular

Â¡Perfecto para demostrar las capacidades de Spark Streaming en un contexto real! ğŸš€

## ğŸ”§ Requisitos del Sistema

- **Python**: 3.7 o superior
- **Java**: 8 o 11 (para PySpark)
- **RAM**: MÃ­nimo 4GB recomendado
- **SO**: Windows/Linux/macOS

## ğŸ“ˆ Datos Generados

### CSV BÃ¡sico (`propiedades.csv`)
- title, price, location, rooms, bathrooms, area_m2, publisher, url

### Streaming JSON (formato enriquecido)
- Todos los campos anteriores +
- timestamp, property_type, amenities, condition, construction_year
- price_per_m2, floors, parking, description

## ğŸ¯ Casos de Uso Demostrados

1. **ETL en Tiempo Real**: ExtracciÃ³n, transformaciÃ³n y carga continua
2. **AnÃ¡lisis de Mercado**: EstadÃ­sticas de precios en vivo
3. **Alertas AutomÃ¡ticas**: DetecciÃ³n de propiedades premium
4. **Calidad de Datos**: Limpieza y validaciÃ³n en streaming
5. **Agregaciones Complejas**: MÃºltiples mÃ©tricas simultÃ¡neas

## ğŸš¨ Troubleshooting

### Error: "Java not found"
```bash
# Instalar Java 11
# Windows: Descargar desde Oracle/OpenJDK
# Linux: sudo apt install openjdk-11-jdk
# macOS: brew install openjdk@11
```

### Error: "No module named pyspark"
```bash
pip install pyspark==3.4.1
```

### Sin datos en streaming
```bash
# Verificar directorio
ls streaming_data/

# Regenerar datos
python synthetic_data_generator.py
```

## ğŸ“ Notas Importantes

- **Streaming Data**: Los archivos JSON se generan en `streaming_data/`
- **Rate Limiting**: 2 segundos entre requests para respetar el servidor
- **Memory**: Spark usa ~2GB RAM por defecto
- **Performance**: Mejor rendimiento con SSD

## ğŸ“ Conceptos Demostrados

- **Spark Streaming**: Procesamiento micro-batch
- **Structured Streaming**: API moderna de Spark
- **Window Functions**: AnÃ¡lisis temporal
- **Watermarking**: Manejo de datos tardÃ­os
- **Multiple Sinks**: MÃºltiples outputs simultÃ¡neos
- **Schema Evolution**: Manejo de cambios de estructura

---

## ğŸ† Â¿Por quÃ© este proyecto es ideal para mostrar Spark Streaming?

1. **âœ… Datos Realistas**: Propiedades inmobiliarias reales
2. **âœ… Flujo Continuo**: Datos llegan gradualmente
3. **âœ… AnÃ¡lisis Variados**: 5 tipos diferentes de consultas
4. **âœ… Escalabilidad**: FÃ¡cil agregar mÃ¡s fuentes de datos
5. **âœ… VisualizaciÃ³n**: Resultados claros en consola
6. **âœ… PrÃ¡ctica Real**: Caso de uso empresarial tÃ­pico

Â¡Perfecto para demostrar las capacidades de Spark Streaming! ğŸš€
