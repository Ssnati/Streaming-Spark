# ğŸ  AnÃ¡lisis de Propiedades Inmobiliarias con Spark

Proyecto de anÃ¡lisis de datos inmobiliarios que combina web scraping con procesamiento en tiempo real utilizando Apache Spark 3.4.1. El sistema estÃ¡ diseÃ±ado para monitorear un directorio y analizar datos de archivos CSV a medida que llegan, ofreciendo dos modos de anÃ¡lisis distintos.

## ğŸš€ CaracterÃ­sticas Principales

### ğŸ” Web Scraping
- **`web_scraper.py`**: Script para extraer propiedades de portales inmobiliarios.
- Soporta paginaciÃ³n automÃ¡tica para obtener un gran volumen de datos.
- Extrae y limpia informaciÃ³n clave como precio, Ã¡rea, barrio y publicador.
- Guarda los resultados en archivos CSV individuales dentro de la carpeta `files/csv`.

### ğŸ“Š Procesamiento de Datos con Spark Streaming
El proyecto ofrece dos enfoques para el anÃ¡lisis de datos en tiempo real:

1.  **AnÃ¡lisis Uno por Uno (`streaming_analysis_one_by_one.py`)**:
    - Procesa cada nuevo archivo CSV de forma individual e independiente.
    - Ideal para ver el impacto y las caracterÃ­sticas de cada lote de datos nuevo.

2.  **AnÃ¡lisis Acumulativo (`streaming_analysis_acumulative.py`)**:
    - Cada vez que se aÃ±ade un nuevo archivo, vuelve a analizar el **conjunto completo** de datos en la carpeta.
    - Proporciona una visiÃ³n global y actualizada del mercado con toda la informaciÃ³n disponible.

3.  **AnÃ¡lisis "Todo en Uno" (`all_in_one_streaming.py`)**:
    - Un script avanzado que combina mÃºltiples tÃ©cnicas de streaming en una sola ejecuciÃ³n:
    - **Conteo por Ventanas de Tiempo**: Analiza la frecuencia de palabras en los tÃ­tulos de las propiedades en ventanas de tiempo deslizantes.
    - **ExtracciÃ³n de Palabras con NÃºmeros**: Identifica y extrae palabras que contienen dÃ­gitos en cualquier campo de texto.
    - **UniÃ³n de MÃºltiples Flujos**: Combina y procesa datos de dos directorios de entrada (`files/csv` y `files/csv2`) simultÃ¡neamente.

#### MÃ©tricas Generadas en Cada AnÃ¡lisis:
- **MÃ©tricas por Barrio**: Conteo de propiedades, precio promedio y precio por mÂ².
- **EstadÃ­sticas Generales**: Resumen total de propiedades y promedios generales.
- **Tendencias de Precios**: Rango de precios (mÃ­nimo y mÃ¡ximo).
- **Top 5 Barrios MÃ¡s Caros**: ClasificaciÃ³n basada en el precio promedio.
- **Propiedades Destacadas**: Una tabla detallada con la propiedad mÃ¡s cara y la mÃ¡s barata del conjunto de datos analizado.

## ğŸ› ï¸ InstalaciÃ³n

### Requisitos
- Python 3.7+
- Java 8 o 11 (Requerido)
- MÃ­nimo 4GB de RAM
- Sistema Operativo: Linux o macOS

### Pasos de InstalaciÃ³n
```bash
# 1. Clonar el repositorio
git clone https://github.com/Ssnati/Streaming-Spark.git
cd Streaming-Spark

# 2. Verificar la version de Java
java -version
# En caso de no ser la requerida, instalar la 11 y cambiarla en el sistema operativo
sudo apt-get install openjdk-11-jdk
sudo update-alternatives --config java

# 3. Crear y activar un entorno virtual
# En Linux/macOS
python3 -m venv .venv
source .venv/bin/activate

# 4. Instalar las dependencias
pip install -r requirements.txt
```

## ğŸš€ Uso

### Paso 1: Extraer Datos (Opcional)
> **Recuerda que, de ahora en adelante, debes ejecutar los comandos con `sudo` para evitar problemas de permisos y para que los archivos se guarden correctamente.**

Si no tienes archivos CSV, puedes generarlos con el scraper. Los archivos se guardarÃ¡n en `files/csv/`.

```bash
# Extraer datos de las primeras 3 pÃ¡ginas
python web_scraper.py --pages 3

# O solo de la primera pÃ¡gina
python web_scraper.py --single
```

### Paso 2: Ejecutar un AnÃ¡lisis en Tiempo Real
Elige uno de los dos modos de anÃ¡lisis. El script comenzarÃ¡ a monitorear la carpeta `files/csv`. Puedes aÃ±adir, mover o eliminar archivos CSV en esa carpeta para ver cÃ³mo se actualiza el anÃ¡lisis.

**OpciÃ³n A: AnÃ¡lisis Uno por Uno**
```bash
python streaming_analysis_one_by_one.py
```

**OpciÃ³n B: AnÃ¡lisis Acumulativo**
```bash
python streaming_analysis_acumulative.py
```

**OpciÃ³n C: AnÃ¡lisis "Todo en Uno"**
```bash
python all_in_one_streaming.py
```

> **Tips:** Para ver como se actualiza el stream y la consola, ejecuta en otra terminal el script para scrapear datos con una pÃ¡gina mÃ¡s. De esta forma, el anÃ¡lisis en tiempo real detectarÃ¡ los nuevos archivos CSV y mostrarÃ¡ los resultados actualizados.

*Presiona `Ctrl+C` en la terminal para detener el script de anÃ¡lisis.*

## ğŸ“ Estructura del Proyecto
```
.
â”œâ”€â”€ checkpoints/              # Directorios para los puntos de control de Spark
â”œâ”€â”€ files/
â”‚   â””â”€â”€ csv/                # Carpeta monitoreada para archivos CSV de entrada
â”œâ”€â”€ .venv/                    # Entorno virtual de Python
â”œâ”€â”€ web_scraper.py            # Script de web scraping
â”œâ”€â”€ streaming_analysis_one_by_one.py # AnÃ¡lisis de streaming (archivo por archivo)
â”œâ”€â”€ streaming_analysis_acumulative.py  # AnÃ¡lisis de streaming (acumulativo)
â”œâ”€â”€ all_in_one_streaming.py        # Script con mÃºltiples anÃ¡lisis de streaming
â”œâ”€â”€ requirements.txt          # Dependencias del proyecto
â””â”€â”€ README.md                 # Este archivo
```

## ğŸ› ï¸ SoluciÃ³n de Problemas

- **Error de `pyspark` no encontrado**: AsegÃºrate de haber activado el entorno virtual (`source .venv/bin/activate` o `.venv\Scripts\activate`) antes de ejecutar los scripts.
- **Error de Java**: Verifica que Java 8 o 11 estÃ© instalado y que la variable de entorno `JAVA_HOME` estÃ© configurada correctamente.
- **Permisos en Linux/macOS**: Si encuentras errores de permisos, asegÃºrate de que los scripts tengan permisos de ejecuciÃ³n (`chmod +x *.py`).
- **Error de update de linux**: Si encuentras errores de update de linux, ejecuta el siguiente comando:
```bash
sudo apt update
```
- **Java no encontrado o version incorrecta**: La version de Java debe ser 8 o 11. Si encuentras errores de Java, ejecuta el siguiente comando:
```bash
sudo apt install openjdk-11-jdk
sudo update-alternatives --config java
```

## ğŸ‘¥ CrÃ©ditos
<center>
Hecho por Santiago Orjuela, SebastiÃ¡n Rueda y Zarith Gomez
</center>